import torch
import torchvision.transforms as transforms
from PIL import Image
from torchvision.models import vgg19
from torchvision.utils import save_image

import os

# ìŠ¤íƒ€ì¼ ì „ì†¡ì— ì‚¬ìš©í•  ìœ í‹¸ í•¨ìˆ˜
def load_image(image_path, max_size=400, shape=None):
    image = Image.open(image_path).convert('RGB')

    if max(image.size) > max_size:
        size = max_size
    else:
        size = max(image.size)

    if shape is not None:
        size = shape  # ì—¬ê¸°ê°€ tuple (H, W) ì´ì–´ì•¼ í•¨

    # ì—¬ê¸°ì„œ tupleì´ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬í•´ì£¼ì
    if isinstance(size, int):
        resize = transforms.Resize((size, size))  # ì •ì‚¬ê°í˜•
    else:
        resize = transforms.Resize(size)  # ì´ë¯¸ (H, W)

    in_transform = transforms.Compose([
        resize,
        transforms.ToTensor(),
        transforms.Normalize(
            (0.485, 0.456, 0.406),
            (0.229, 0.224, 0.225)
        )
    ])

    image = in_transform(image)[:3, :, :].unsqueeze(0)
    return image

# ì´ë¯¸ì§€ ì €ì¥ í•¨ìˆ˜
def im_convert(tensor):
    image = tensor.to("cpu").clone().detach()
    image = image.numpy().squeeze()
    image = image.transpose(1, 2, 0)
    image = image * [0.229, 0.224, 0.225]
    image = image + [0.485, 0.456, 0.406]
    image = image.clip(0, 1)
    return image

# ìŠ¤íƒ€ì¼ ì „ì†¡ ì‹¤í–‰ í•¨ìˆ˜
def apply_style(content_path, style_path, output_path='output.jpg'):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    content = load_image(content_path).to(device)
    #style = load_image(style_path, shape=content.shape[-2:]).to(device)
    shape = tuple(content.shape[-2:])  # torch.Size â†’ (int, int)
    style = load_image(style_path, shape=shape).to(device)
    # VGG ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    vgg = vgg19(pretrained=True).features.to(device).eval()

    # í•™ìŠµëœ ìŠ¤íƒ€ì¼ ì „ì†¡ ë„¤íŠ¸ì›Œí¬ ì‚¬ìš© ê°€ëŠ¥ (ì˜ˆ: Fast Neural Style)
    # ì—¬ê¸°ì„  ê°„ë‹¨íˆ í•˜ë ¤ VGG ê¸°ë°˜ì„ ì‚¬ìš©í•˜ì§€ë§Œ,
    # ì‹¤ì‚¬ìš©ì—ëŠ” pre-trained ìŠ¤íƒ€ì¼ ë„¤íŠ¸ì›Œí¬ ì¶”ì²œ

    # ğŸŸŸ ë” ê³ ê¸‰ ë²„ì „ì´ í•„ìš”í•˜ë©´ `fast-neural-style`ì„ ì¶”ì²œ:
    # https://github.com/pytorch/examples/tree/main/fast_neural_style

    print("í˜„ì¬ ì´ ì½”ë“œëŠ” ìŠ¤íƒ€ì¼ íŠ¹ì§• ì¶”ì¶œê¹Œì§€ë§Œ ê°€ëŠ¥í•˜ë©°, ì‹¤ì œ ìŠ¤íƒ€ì¼ ë§¤í•‘ì€ êµ¬í˜„ì´ ë” í•„ìš”í•©ë‹ˆë‹¤.")
    # ì°¸ê³ : ì™„ì „í•œ ìŠ¤íƒ€ì¼ ì „ì†¡ ì½”ë“œëŠ” ê½¤ ê¸¸ì–´ì§‘ë‹ˆë‹¤.

# ì˜ˆì‹œ ì‚¬ìš©
apply_style(
    content_path='D:\my_pc_iplist.png',       # ë³€í™˜í•  ì‚¬ì§„
    style_path='D:\ghibli_style.jpg',       # ì§€ë¸Œë¦¬ ìŠ¤íƒ€ì¼ ê·¸ë¦¼ (ì˜ˆ: í•˜ìš¸, ì´ì›ƒì§‘ í† í† ë¡œ ë°°ê²½ ë“±)
    output_path='D:\ghibli_output.jpg'
)
